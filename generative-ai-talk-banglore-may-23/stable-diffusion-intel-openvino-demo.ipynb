{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d727b14e",
   "metadata": {},
   "source": [
    "# Stable diffusion optimization using Intel Openvino and Optimum-intel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1f4b8",
   "metadata": {},
   "source": [
    "Latent Diffusion models are game changers when it comes to solving text-to-image generation problems. Stable Diffusion is one of the most famous examples that got wide adoption in the community and industry. The idea behind the Stable Diffusion model is simple and compelling: you generate an image from a noise vector in multiple small steps refining the noise to a latent image representation.\n",
    "\n",
    "However, such an approach inevitably increases the overall inference time and causes a poor user experience when deployed on a client machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ec449",
   "metadata": {},
   "source": [
    "In this notebook, we will outline the problems of optimizing Stable Diffusion models and propose a workflow that substantially reduces the latency of such models when running on a resource-constrained HW such as CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0242f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.training_utils import set_seed\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cf6f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def elapsed_time(pipeline, prompt, nb_pass=4, num_inference_steps=20):\n",
    "    # warmup\n",
    "    images = pipeline(prompt, num_inference_steps=10).images\n",
    "    start = time.time()\n",
    "    for _ in range(nb_pass):\n",
    "        _ = pipeline(prompt, num_inference_steps=num_inference_steps, output_type=\"np\")\n",
    "    end = time.time()\n",
    "    return (end - start) / nb_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdba821",
   "metadata": {},
   "source": [
    "The Diffusers library makes it extremely simple to generate images with Stable Diffusion models. If you're not familiar with these models, here's a great illustrated [introduction](https://jalammar.github.io/illustrated-stable-diffusion/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd7818",
   "metadata": {},
   "source": [
    "Let's build a StableDiffusionPipeline with the default float32 data type, and measure its inference latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30379260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7ca3bb68b443e5ac3ad87e8e7f6853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f889d567a745eea95383c13319e814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b545d7038f4e56bcc00e06f1334331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec179e20d4254a869b1010f37574e26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4564fbec056f48288d7469fb86910c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.45383483171463\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id)\n",
    "prompt = \"sailing ship in storm by Rembrandt\"\n",
    "latency = elapsed_time(pipe, prompt)\n",
    "print(latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179eeb56",
   "metadata": {},
   "source": [
    "## Optimum Intel and OpenVINO\n",
    "\n",
    "Optimum Intel accelerates end-to-end pipelines on Intel architectures. Its API is extremely similar to the vanilla Diffusers API, making it trivial to adapt existing code.\n",
    "\n",
    "Optimum Intel supports OpenVINO, an Intel open-source toolkit for high-performance inference.\n",
    "\n",
    "Optimum Intel and OpenVINO can be installed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56bf09a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/diffusers/models/cross_attention.py:30: FutureWarning: Importing from cross_attention is deprecated. Please import from diffusers.models.attention_processor instead.\n",
      "  deprecate(\n",
      "Framework not specified. Using pt to export to ONNX.\n",
      "Keyword arguments {'subfolder': '', 'config': {'_class_name': 'StableDiffusionPipeline', '_diffusers_version': '0.6.0', 'feature_extractor': ['transformers', 'CLIPImageProcessor'], 'safety_checker': ['stable_diffusion', 'StableDiffusionSafetyChecker'], 'scheduler': ['diffusers', 'PNDMScheduler'], 'text_encoder': ['transformers', 'CLIPTextModel'], 'tokenizer': ['transformers', 'CLIPTokenizer'], 'unet': ['diffusers', 'UNet2DConditionModel'], 'vae': ['diffusers', 'AutoencoderKL']}} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/diffusers/models/cross_attention.py:51: FutureWarning: CrossAttnProcessor is deprecated and will be removed in `0.18.0`. Please use `from diffusers.models.attention_processor import AttnProcessor instead.\n",
      "  deprecate(\"cross_attention\", \"0.18.0\", deprecation_message, standard_warn=False)\n",
      "Using framework PyTorch: 2.1.0.dev20230609+cpu\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/transformers/models/clip/modeling_clip.py:684: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask = torch.full((tgt_len, tgt_len), torch.tensor(torch.finfo(dtype).min, device=device), device=device)\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/transformers/models/clip/modeling_clip.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/transformers/models/clip/modeling_clip.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if causal_attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/transformers/models/clip/modeling_clip.py:324: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/torch/onnx/symbolic_opset9.py:5765: UserWarning: Exporting aten::index operator of advanced indexing in opset 14 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Diagnostic Run torch.onnx.export version 2.1.0.dev20230609+cpu ========\n",
      "verbose: False, log level: 40\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using framework PyTorch: 2.1.0.dev20230609+cpu\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/diffusers/models/unet_2d_condition.py:686: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if any(s % default_overall_up_factor != 0 for s in sample.shape[-2:]):\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/diffusers/models/resnet.py:214: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/diffusers/models/resnet.py:219: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/diffusers/models/resnet.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert hidden_states.shape[1] == self.channels\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/diffusers/models/resnet.py:151: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if hidden_states.shape[0] >= 64:\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/diffusers/models/unet_2d_condition.py:869: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not return_dict:\n",
      "Saving external data to one file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Diagnostic Run torch.onnx.export version 2.1.0.dev20230609+cpu ========\n",
      "verbose: False, log level: 40\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using framework PyTorch: 2.1.0.dev20230609+cpu\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/torch/onnx/_internal/jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/torch/onnx/utils.py:691: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/ubuntu/miniconda2/envs/optimum/lib/python3.8/site-packages/torch/onnx/utils.py:1198: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "Using framework PyTorch: 2.1.0.dev20230609+cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Diagnostic Run torch.onnx.export version 2.1.0.dev20230609+cpu ========\n",
      "verbose: False, log level: 40\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "======== Diagnostic Run torch.onnx.export version 2.1.0.dev20230609+cpu ========\n",
      "verbose: False, log level: 40\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the text_encoder...\n",
      "Compiling the vae_decoder...\n",
      "Compiling the unet...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceabf440071145089f00e36b96b70347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22a3f4d13ca42aab1d4ebe00c55a79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe38766e0294cee96c23a5d26fcbb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738c235235a1430f962fd9946bea7135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57340c905f44e428a940b175b5b2cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from optimum.intel.openvino import OVStableDiffusionPipeline\n",
    "\n",
    "ov_pipe = OVStableDiffusionPipeline.from_pretrained(model_id, export=True)\n",
    "latency = elapsed_time(ov_pipe, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09bdaad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.661957800388336\n"
     ]
    }
   ],
   "source": [
    "print(latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3f306",
   "metadata": {},
   "source": [
    "The pipeline above support dynamic input shapes, with no restriction on the number of images or their resolution. With Stable Diffusion, your application is usually restricted to one (or a few) different output resolutions, such as 512x512, or 256x256. Thus, it makes a lot of sense to unlock significant acceleration by reshaping the pipeline to a fixed resolution. If you need more than one output resolution, you can simply maintain a few pipeline instances, one for each resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c82a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the text_encoder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b4052969134ffb9bb3c64938fb5ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the unet...\n",
      "Compiling the vae_decoder...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db841346f3048318423603caa1d6c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf600496dc54626985781e411ef98cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d322165ddc6e40a0a097b813222047fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3caa560be14dc29cf1eaffef7613b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ov_pipe.reshape(batch_size=1, height=512, width=512, num_images_per_prompt=1)\n",
    "latency = elapsed_time(ov_pipe, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac2fba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.09998345375061\n"
     ]
    }
   ],
   "source": [
    "print(latency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
